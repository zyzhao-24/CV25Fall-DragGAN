# CV25Fall-DragGAN 项目结构说明

## 项目概述

本项目是北京大学计算机视觉课程（CV25Fall）的DragGAN项目，包含DragGAN的原始实现、改进版本（Task2）以及其他相关研究。

## 目录结构

### 根目录文件

```
.
├── Milestone_DragGAN_赵泽宇_王唐欣宇_鄢宇阳.pdf  # 项目里程碑报告
├── ProjectDirections.pdf                         # 项目指导文档
├── README.md                                     # 项目主README
├── 项目结构说明.md                               # 本文件
├── DragDiffusion/                                # DragDiffusion实现
├── DragGAN/                                      # 原始DragGAN实现
├── Paper/                                        # 相关论文
├── Task2/                                        # DragGAN改进版本（Task2）
└── UserControllableLT/                           # 用户可控潜在变换研究
```

## Task2 - DragGAN改进版本详细分析

### Task2目录结构

```
Task2/
├── core.py                    # 核心算法实现
├── visualizer.py              # Gradio GUI界面主程序
├── demo.py                    # 演示脚本
├── legacy.py                  # 旧版本兼容性代码
├── run_raft_example.py        # RAFT示例运行脚本
├── arial.ttf                  # 字体文件
├── dnnlib/                    # 基础工具库
│   ├── __init__.py
│   └── util.py
├── docs/                      # 文档和分析
│   ├── DragGAN_analysis.md    # DragGAN分析文档
│   ├── inplace.md
│   ├── Renderer_Analysis.md
│   └── tracking.md
├── example/                   # 示例数据
│   └── points_log.txt
├── gradio_utils/              # Gradio工具函数
│   ├── __init__.py
│   └── utils.py
├── raft/                      # RAFT光流模型实现
│   ├── __init__.py
│   ├── corr.py
│   ├── datasets.py
│   ├── extractor.py
│   ├── raft.py
│   ├── update.py
│   └── utils/
├── torch_utils/               # PyTorch工具
│   ├── __init__.py
│   ├── custom_ops.py
│   ├── misc.py
│   ├── persistence.py
│   ├── training_stats.py
│   └── ops/
├── training/                  # 训练相关代码
│   ├── __init__.py
│   ├── augment.py
│   ├── dataset.py
│   ├── loss.py
│   ├── networks_stylegan2.py
│   └── training_loop.py
└── viz/                       # 可视化组件
    ├── __init__.py
    ├── capture_widget.py
    ├── drag_widget.py
    ├── latent_widget.py
    ├── pickle_widget.py
    └── renderer.py
```

### Task2核心功能模块

#### 1. 核心算法 (`core.py`)
- **特征计算**：从StyleGAN生成器提取多层特征
- **点跟踪**：
  - `point_tracking_L2_point`：基于L2距离的特征匹配
  - `point_tracking_raft`：基于RAFT光流的点跟踪
- **运动监督**：`motion_supervision`函数，优化潜在编码
- **主渲染循环**：`render_drag_impl`函数，协调整个拖拽过程

#### 2. GUI界面 (`visualizer.py`)
- **Gradio Web界面**：提供交互式图像编辑界面
- **状态管理**：`global_state`字典管理所有编辑状态
- **事件处理**：处理用户交互事件（点击、按钮等）
- **Mask编辑**：支持灵活区域和固定区域的mask编辑

#### 3. 可视化组件 (`viz/`)
- **拖拽部件** (`drag_widget.py`)：
  - 控制点管理
  - Mask绘制（圆形区域）
  - 拖拽参数设置
- **渲染器** (`renderer.py`)：
  - StyleGAN模型加载和管理
  - 潜在空间优化
  - 图像生成和渲染

#### 4. Gradio工具 (`gradio_utils/utils.py`)
- **自定义组件**：`ImageMask`支持sketch工具
- **绘制函数**：`draw_points_on_image`, `draw_mask_on_image`
- **Mask处理**：`get_valid_mask`转换mask格式

### Task2的主要改进

#### 1. RAFT光流跟踪
- **原始方法**：仅使用L2特征匹配进行点跟踪
- **改进方法**：引入RAFT（Recurrent All-Pairs Field Transforms）光流模型
- **优势**：更准确的点跟踪，特别是在大运动和复杂场景中

#### 2. 增强的Mask编辑
- **两种模式**：
  - `flexible`：可编辑区域（mask值为0）
  - `fixed`：固定区域（mask值为1）
- **交互式绘制**：支持实时绘制和修改mask
- **可视化**：半透明显示mask区域

#### 3. 改进的GUI
- **参数控制**：更细粒度的参数调整
- **实时反馈**：步骤间隔显示优化进度
- **状态管理**：更好的编辑状态持久化

### 算法流程

1. **初始化阶段**
   - 加载预训练的StyleGAN模型
   - 生成初始图像和潜在编码
   - 初始化优化器（Adam）

2. **用户交互阶段**
   - 用户添加控制点（起点和目标点）
   - 用户绘制mask定义编辑区域
   - 设置算法参数（学习率、半径等）

3. **拖拽优化阶段**
   - **运动监督**：计算特征空间中的运动方向，优化潜在编码
   - **点跟踪**：使用RAFT或L2跟踪控制点位置
   - **Mask约束**：限制编辑区域，保护固定区域
   - **迭代优化**：重复上述步骤直到收敛或用户停止

4. **结果输出**
   - 生成最终编辑图像
   - 保存控制点和mask信息
   - 提供下载功能

### 关键技术点

#### 1. 特征提取
- 使用StyleGAN生成器的中间层特征
- 特征索引`feature_idx=5`（可配置）
- 双线性插值调整特征图大小

#### 2. 运动监督
- 在特征空间中计算控制点运动方向
- 使用L1损失优化潜在编码
- 半径参数`r1`控制运动监督范围

#### 3. 点跟踪
- **L2方法**：在局部特征块中寻找最相似的特征
- **RAFT方法**：使用光流估计点位移
- 半径参数`r2`控制跟踪搜索范围

#### 4. Mask约束
- Lambda参数`lambda_mask`控制约束强度
- 保护固定区域的特征不变性
- 支持动态修改mask

### 文件依赖关系

```
visualizer.py (主GUI)
    ├── core.py (核心算法)
    │   ├── raft/ (光流模型)
    │   └── torch
    ├── viz/renderer.py (渲染器)
    │   ├── legacy.py (模型加载)
    │   └── training/ (网络架构)
    ├── gradio_utils/utils.py (GUI工具)
    └── dnnlib/ (基础工具)
```

### 运行方式

1. **安装依赖**：
   ```bash
   pip install -r requirements.txt
   ```

2. **下载预训练模型**：
   - 将模型文件放入`checkpoints/`目录

3. **启动GUI**：
   ```bash
   python visualizer.py
   ```

4. **访问Web界面**：
   - 打开浏览器访问 `http://localhost:7860`

### 与其他目录的关系

#### 1. 与原始DragGAN (`DragGAN/`) 的关系
- Task2基于原始DragGAN进行改进
- 保留了核心架构和算法思想
- 主要改进：RAFT跟踪、增强Mask编辑、改进GUI

#### 2. 与DragDiffusion (`DragDiffusion/`) 的关系
- 不同的技术路线：DragGAN基于GAN，DragDiffusion基于扩散模型
- 相似的用户交互：都支持基于点的图像编辑
- 独立但相关的实现

#### 3. 与UserControllableLT (`UserControllableLT/`) 的关系
- 相关研究：用户可控的潜在变换
- 可能的技术互补：潜在空间编辑技术

### 扩展和定制

#### 1. 添加新模型
- 在`checkpoints/`目录中添加新的.pkl模型文件
- 修改`visualizer.py`中的模型选择逻辑

#### 2. 修改算法参数
- 核心参数在`core.py`的`render_drag_impl`函数中
- GUI参数在`visualizer.py`的`global_state`中

#### 3. 扩展功能
- 添加新的点跟踪方法
- 支持更多的mask形状
- 添加批量处理功能

### 注意事项

1. **硬件要求**：
   - GPU推荐（用于RAFT和StyleGAN推理）
   - 足够的内存（模型加载和特征存储）

2. **软件依赖**：
   - PyTorch >= 1.7.0
   - Gradio >= 3.0.0
   - 其他依赖见`requirements.txt`

3. **模型兼容性**：
   - 支持StyleGAN2/3的.pkl格式模型
   - 可能需要调整网络架构参数

### 总结

Task2是DragGAN的一个功能增强版本，主要改进包括：
1. **更准确的点跟踪**：引入RAFT光流模型
2. **更灵活的编辑控制**：增强的mask编辑功能
3. **更好的用户体验**：改进的GUI界面和交互

该实现保持了模块化设计，便于进一步的研究和开发。核心算法逻辑清晰，各功能模块分离良好，具有良好的可维护性和扩展性。
